Notes for both programs:

These are command line programs. They require Windows, as they use the Video
For Windows (VFW) APIs to read and write .avi files.

It may be necessary to install the runtime for Microsoft Visual C++ before
running the program. This can be found at
https://aka.ms/vs/16/release/vc_redist.x86.exe .




Notes specific to avi2ntsc:

Syntax: avi2ntsc <name of avi file to convert>

For best results, the input should be an .avi file of resolution 768x480 with
an aspect ratio of 4:3 (pixel aspect ratio 5:6). VirtualDub
( http://www.virtualdub.org/ ) can be used to resize and/or crop videos to
put them in this format. The frame rate of the video should 60fps (or more
accurately 59.94fps: 60/1.001) or the playback speed will be wrong after

I used the UtVideo RGB VCM codec ( https://github.com/umezawatakeshi/utvideo/ )
for both reading and writing. Other codecs supported by Video For Windows
should work fine.

avi2ntsc will generate a file with the same name as the input file, with .ntsc
appended to the end. This file will be in raw 8-bit unsigned PCM format sampled
at a rate of 14.318MHz (4 times the NTSC color carrier frequency). Note that
this is not a .wav file as a lot of software assumes that .wav files are of
audio frequencies and could get confused by a .wav file with such a high sample
rate, potentially leading to crashes and data loss. Most software designed for
editing/processing .wav files (e.g. Adobe Audition) can open raw files with
whatever frequency you set, though you may need to rename the file to have the
extension .raw or .pcm.

The file (if renamed with the extension .bin) can also be opened in VirtualDub.
Use frame rate = 59.97, width 910, height 525, scan line alignment 1. Because
the file is interlaced, you will see two fields per frame, one above the other.
This is a good way to visualise the sync pulses (including
equalisation/serration), color burst and color carrier.

The file should conform to the 8-bit composite digital standard SMPTE 244M,
byte value = IRE x 1.4 + 60. There are more details about this standard in
chapter 11 "The World of Digital Video" of Dirty Pixels by Jim Blinn.


Notes specific to ntsc2avi:

Syntax: ntsc2avi <name of ntsc file to convert>

Various parameters are configurable - see default.config for details.

When starting the program for the first time there will be a delay while
optimal FFT parameters are computed. These will be saved in a file called
"wisdom" for faster startup next time.

After FFT initialization, a dialog pops up allowing you to select a video codec
from those installed on the system, and choose parameters for the codec. If
using x264vfw it may be necessary to disable logging or the program may stall.

ntsc2avi will generate an output file with the same name as the input file. By
default, this will be a 640x480 progressive (480p) file at 59.94fps, even if
the source material is interlaced. ntsc2avi simulates a TV/monitor, so the
interlacing in the output file looks as it would on an actual device. With the
default settings, removing every other line (nearest neighbour resize to
640x240) should allow the file to be a good source for typical deinterlacing
algorithms.

.ntsc files generated by gapless capture of a real composite source should work
fine, though there may be banding if the the capture device's pixel clock is
not exactly 4 times the color carrier. If you have this problem, let me know as
I have another decoding algorithm which may work better. If you have a need to
make gapless captures in real-time from a composite source, also let me know as
I have some ideas about how to do this using inexpensive components. Likewise
for the reverse direction (outputting an .ntsc to a TV or VCR, for example).


Ideas for future improvements:

* Some kind of user interface, for viewing files and changing parameters in
real time.
* Automatic gain control (normalizing the signal by checking the amplitude of
the burst pulse, or the horizontal sync pulse if there is no burst pulse) as
a real TV or monitor does.
* Proper implementation of the color killer circuit (including hysteresis) to
automatically improve image sharpness for signals which do not have a colour
component.
* Sub-sample horizontal alignment (currently the hsync signals are only found
to an accuracy of 1 sample).
* Use of GPU for faster NTSC decoding and scaling.
* Your suggestion here.


Andrew Jenner (andrew@reenigne.org)
July 2020
